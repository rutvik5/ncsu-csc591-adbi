{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y = True)\n",
    "# Predict only if versicolor or not\n",
    "y = np.array([1 if ele == 2 else 0 for ele in y])\n",
    "\n",
    "#split data into train and test modules\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.zeros((4,1))\n",
    "learning_rate = 0.01\n",
    "parameter_constraint = 1\n",
    "iterations = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(beta, parameter_constraint, X, y, learning_rate):\n",
    "    perm = np.random.permutation(X.shape[0])[:10]\n",
    "    for i in perm:\n",
    "        beta_prev = beta\n",
    "        x = np.array([X[i]])\n",
    "        for j in range(4):\n",
    "            delta = learning_rate * (parameter_constraint * beta_prev[j] + X[i][j] * (np.matmul(x,beta_prev))-y[i])\n",
    "            beta[j][0] = beta_prev[j][0] - delta\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner(beta, parameter_constraint, X, y, learning_rate, iterations):\n",
    "    print('Training begins********')\n",
    "    for i in range(iterations):\n",
    "        beta = step_gradient(beta, parameter_constraint, X, y, learning_rate)\n",
    "        if i%100 ==0:\n",
    "            print('Iteration #',i, ': weights: ', beta[0], ' ', beta[1], ' ', beta[2], ' ', beta[3], ' ')\n",
    "    print('Training ends******** ')\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X,y,beta):\n",
    "    error = 0\n",
    "    for ind,row in enumerate(X):\n",
    "        y_hat = 0\n",
    "        for ind2,ele in enumerate(row):\n",
    "            y_hat += beta[ind2]*ele\n",
    "        error += (y[ind] - y_hat)**2\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins********\n",
      "Iteration # 0 : weights:  [0.00556453]   [0.01691002]   [0.00631966]   [0.01989212]  \n",
      "Iteration # 100 : weights:  [-0.07513817]   [0.10943035]   [-0.00819148]   [0.1855857]  \n",
      "Iteration # 200 : weights:  [-0.11315599]   [0.1543553]   [-0.02504014]   [0.25260467]  \n",
      "Iteration # 300 : weights:  [-0.06992392]   [0.09876123]   [-0.01294016]   [0.17143019]  \n",
      "Iteration # 400 : weights:  [-0.09954371]   [0.14466709]   [-0.02112313]   [0.23581418]  \n",
      "Iteration # 500 : weights:  [-0.08260029]   [0.11970077]   [-0.00917453]   [0.20036581]  \n",
      "Iteration # 600 : weights:  [-0.08849852]   [0.12196856]   [-0.01934849]   [0.20072561]  \n",
      "Iteration # 700 : weights:  [-0.08989027]   [0.14100194]   [-0.02228397]   [0.22833981]  \n",
      "Iteration # 800 : weights:  [-0.08074328]   [0.12963661]   [-0.01313432]   [0.20651157]  \n",
      "Iteration # 900 : weights:  [-0.11163106]   [0.14430855]   [-0.01927251]   [0.24811786]  \n",
      "Iteration # 1000 : weights:  [-0.10338695]   [0.15864219]   [-0.02396726]   [0.251814]  \n",
      "Iteration # 1100 : weights:  [-0.0931712]   [0.11964197]   [-0.01516252]   [0.20948895]  \n",
      "Iteration # 1200 : weights:  [-0.09270015]   [0.13311831]   [-0.01566082]   [0.21772205]  \n",
      "Iteration # 1300 : weights:  [-0.12318258]   [0.14440509]   [-0.02527296]   [0.24990588]  \n",
      "Iteration # 1400 : weights:  [-0.10145458]   [0.13516636]   [-0.01991176]   [0.22637607]  \n",
      "Iteration # 1500 : weights:  [-0.08627565]   [0.14533878]   [-0.01083863]   [0.23305004]  \n",
      "Iteration # 1600 : weights:  [-0.08210064]   [0.11214922]   [-0.01468005]   [0.19436049]  \n",
      "Iteration # 1700 : weights:  [-0.0926436]   [0.13545823]   [-0.0153916]   [0.22767399]  \n",
      "Iteration # 1800 : weights:  [-0.10276479]   [0.13894439]   [-0.01922437]   [0.22828033]  \n",
      "Iteration # 1900 : weights:  [-0.09969471]   [0.14519655]   [-0.01962328]   [0.23289684]  \n",
      "Training ends******** \n",
      "\n",
      "Weight values after training [-0.10051397]   [0.14529713]   [-0.01471264]   [0.23539909]  \n",
      "Error between train and test datasets:  [2.18412523]\n"
     ]
    }
   ],
   "source": [
    "beta = gradient_descent_runner(beta, parameter_constraint, X_train, y_train, learning_rate, iterations)\n",
    "print()\n",
    "print('Weight values after training', beta[0], ' ', beta[1], ' ', beta[2], ' ', beta[3], ' ')\n",
    "print('Error between train and test datasets: ', error(X_test,y_test,beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
